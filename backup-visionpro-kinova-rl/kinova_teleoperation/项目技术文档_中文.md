# Kinova Gen3 机器人遥操作系统 - 项目技术文档

## 项目概述

这是一个基于 Apple Vision Pro 手部追踪的 Kinova Gen3 七自由度机械臂实时遥操作系统，用于采集高质量的人类演示数据，支持强化学习（HIL-SERL）框架的数据收集需求。

**核心价值**：实现人类操作者通过自然的手部动作直接控制机械臂，并自动记录演示数据用于机器学习训练。

### 技术指标

- **控制频率**：20Hz 实时控制循环
- **延迟**：<50ms 端到端延迟（Vision Pro → 机器人）
- **安全性**：多层看门狗机制 + 工作空间约束
- **数据质量**：时间戳对齐精度 <50ms，HDF5 格式存储

### 应用场景

- 机器人学习演示数据采集（Imitation Learning）
- 强化学习人在回路训练（HIL-SERL）
- 机器人遥操作任务执行
- 人机交互研究

---

## 技术架构

### 系统组成

```
输入层                控制层              执行层              数据层
┌─────────────┐    ┌──────────────┐    ┌──────────┐    ┌────────────┐
│ Vision Pro  │───▶│ 参考系管理器  │───▶│          │    │            │
│  (20Hz)     │    │ + 滤波器      │    │  逆运动学 │───▶│ ROS2 控制器│
└─────────────┘    └──────────────┘    │   求解器  │    │  (kortex)  │
                                       │          │    └────────────┘
┌─────────────┐    ┌──────────────┐    └──────────┘           │
│  游戏手柄    │───▶│  输入聚合器   │                           ▼
│  (Xbox)     │    │  + 状态机    │                    ┌─────────────┐
└─────────────┘    └──────────────┘                    │ Kinova Gen3 │
                          │                            │  机械臂     │
                          ▼                            └─────────────┘
                   ┌──────────────┐
                   │  安全监控器   │
                   │  (看门狗)    │
                   └──────────────┘
                          │
                          ▼
                   ┌──────────────┐
                   │  数据记录器   │
                   │  (HDF5)      │
                   └──────────────┘
```

### 技术栈

| 层级 | 技术选型 | 说明 |
|------|---------|------|
| **硬件层** | Vision Pro + Kinova Gen3 + Xbox手柄 | 追踪设备 + 机械臂 + 输入设备 |
| **通信层** | gRPC (Vision Pro) + ROS2 (Robot) | 20Hz 流式传输 + 机器人控制 |
| **控制层** | Python 3.8+ | 主控制逻辑 |
| **运动学** | KDL (Kinematics and Dynamics Library) | IK/FK 求解器 |
| **滤波器** | OneEuroFilter | 自适应低延迟平滑 |
| **数据存储** | HDF5 | 多模态数据存储 |
| **中间件** | ROS2 Humble | 机器人操作系统 |

---

## 核心模块详解

### 模块 1：ReferenceFrameManager（参考系管理器）

**功能**：将 Vision Pro 的头部相对坐标转换为世界固定坐标，并进行滤波处理。

**技术难点**：
- Vision Pro 输出的是相对于头部的手部位姿，当用户移动头部时会产生抖动
- 需要在系统启动时"锚定"一个世界坐标系作为参考

**实现方案**：
```python
# 坐标转换公式
P_world = H_init^(-1) × H_current × P_hand_relative

其中：
- H_init: 初始校准时的头部位姿（4×4 变换矩阵）
- H_current: 当前头部位姿
- P_hand_relative: 手部相对头部的位姿
- P_world: 世界坐标系下的手部位姿
```

**关键代码逻辑**：
1. 用户启动系统时保持头部静止，按 Enter 键捕获初始头部位姿 `H_init`
2. 运行时实时计算 `H_init` 的逆矩阵，转换当前手部位姿
3. 应用 OneEuroFilter 对位置坐标进行滤波（消除高频抖动）
4. 同时输出速度估计，用于后续的轨迹预测

**参数调优**：
- `min_cutoff=1.0 Hz`：最小截止频率（控制平滑程度）
- `beta=0.05`：速度自适应系数（手快速移动时减少滤波）
- `d_cutoff=1.0 Hz`：导数截止频率（速度估计平滑度）

---

### 模块 2：InputAggregator（输入聚合器）

**功能**：处理游戏手柄输入，实现离合器（clutch）逻辑和双模式切换。

**按键映射**（Xbox 手柄）：
| 按键 | 功能 | 实现细节 |
|------|------|---------|
| A 键 | 离合器（Clutch） | **按下时**启用遥操作，**松开时**机器人保持位置 |
| Y 键 | 模式切换 | 快速模式（1.5×）↔ 精确模式（0.5×） |
| 右扳机 | 夹爪控制 | 模拟量 0.0（全开）～ 1.0（全闭） |
| B 键 | 紧急停止 | 立即停止所有运动 |

**技术实现亮点**：

1. **边沿检测（Edge Detection）**：
   - 检测 A 键从"未按下"到"按下"的瞬间（上升沿）
   - 只有在上升沿时才设置锚点（anchor），避免锚点漂移

   ```python
   clutch_just_pressed = current_clutch and not prev_clutch
   if clutch_just_pressed:
       # 仅在此刻设置锚点，后续按住期间不再更新
       anchor_hand_pose = current_hand_pose
       anchor_robot_pose = current_robot_pose
   ```

2. **死区处理（Deadband）**：
   - 扳机值 < 0.1 时视为 0（消除零点漂移）
   - 超过死区后重新映射到 [0, 1] 范围

3. **后台线程监听**：
   - 使用独立线程持续读取手柄事件
   - 主控制循环只需调用 `get_state()` 获取最新状态（线程安全）

---

### 模块 3：SafetyMonitor（安全监控器）

**功能**：多层安全保护，防止机器人碰撞、失控或数据异常。

**看门狗机制（Watchdog）**：

| 检测项 | 阈值 | 触发条件 | 响应动作 |
|--------|------|---------|---------|
| **视觉延迟** | 200ms | Vision Pro 数据超时 | 立即停止，断开离合器 |
| **IK 失败** | 连续 5 次 | 逆运动学求解失败 | 停止运动，记录错误 |
| **关节误差** | 0.2 rad | 实际关节角与指令偏差过大（卡死检测） | 紧急停止 |
| **追踪质量** | High | Vision Pro 置信度下降 | 警告并准备停止 |

**工作空间限制**（圆柱坐标系）：

```python
# Z 轴（垂直方向）
z_min = table_height + 0.03m  # 桌面高度 + 3cm 安全裕量
z_max = 1.0m                  # 机器人基座上方 1 米

# XY 平面（水平方向）
r_max = 0.6m                  # 距离基座中心 60cm 圆柱范围

# 超出边界时的处理
if target_z < z_min:
    target_z = z_min  # 箝位到最低安全高度
if sqrt(x² + y²) > r_max:
    # 等比例缩放到边界
    scale = r_max / sqrt(x² + y²)
    x *= scale
    y *= scale
```

**桌面高度校准流程**：
1. 手动移动机器人末端执行器接触桌面
2. 运行 `calibrate_table.py` 脚本
3. 通过正运动学（FK）计算当前 TCP 的 Z 坐标
4. 保存到配置文件 `safety_params.yaml`

---

### 模块 4：MotionPlanner（运动规划器）

**功能**：求解逆运动学（IK）并生成预测性轨迹。

**逆运动学求解**：

使用 KDL 库的 Newton-Raphson 迭代法：

```
输入：
- target_position: 目标笛卡尔位置 [x, y, z]
- target_rotation: 目标旋转矩阵 (3×3)
- seed_joints: 种子关节角（当前关节位置，用于温启动）

输出：
- joint_positions: 7 个关节角度 [θ₁, θ₂, ..., θ₇]
- 或 None（求解失败时）

参数：
- max_iterations = 20（最大迭代次数）
- position_tolerance = 1mm（位置误差容限）
```

**温启动（Warm Start）**技术：
- 每次求解 IK 时，使用上一时刻的关节角作为初值
- 显著提高求解速度（相邻时刻关节角变化小）
- 避免跳变到其他可行解（Kinova 有多个 IK 解）

**预测性轨迹生成**（Predictive Trajectory）：

生成 3 点滑动窗口：t+50ms, t+100ms, t+150ms

```python
# 基于手部速度的线性外推
for future_time in [0.10, 0.15]:
    # 外推位置
    delta_t = future_time - 0.05
    extrapolated_pos = current_ee_pos + hand_velocity * delta_t

    # 速度钳位（防止过快）
    hand_velocity = clip(hand_velocity, -0.5, 0.5)  # m/s

    # 为外推点求解 IK
    future_joints = solve_ik(extrapolated_pos, rotation, seed=current_target)
```

**为什么需要预测**：
- 补偿系统延迟（感知→计算→执行约 50-100ms）
- 提前规划轨迹，使机器人运动更流畅
- 减少"追赶"现象（机器人总是滞后于手部运动）

---

### 模块 5：DataLogger（数据记录器）

**功能**：记录多模态演示数据，用于机器学习训练。

**HDF5 数据结构**（兼容 HIL-SERL）：

```
demonstrations/demo_20250130_143022.hdf5
├── observations/
│   ├── images          (N, 480, 640, 3) uint8   # 相机图像
│   ├── qpos            (N, 7) float32           # 关节位置
│   ├── qvel            (N, 7) float32           # 关节速度
│   └── ee_pose         (N, 7) float32           # 末端位姿 [x,y,z,qx,qy,qz,qw]
├── actions/
│   ├── cartesian_delta (N, 6) float32           # 笛卡尔增量 [Δx,Δy,Δz,Δrx,Δry,Δrz]
│   └── joint_positions (N, 7) float32           # 目标关节位置
└── metadata/
    ├── task_name       "pick_and_place"
    ├── start_time      "2025-01-30T14:30:22"
    ├── num_frames      342
    └── dropped_frames  3
```

**时间戳对齐策略**：

问题：相机图像、机器人状态、动作指令来自不同线程，时间戳不同步。

解决方案：
```python
# 以机器人状态为基准，查找最近的图像
delta_t = |image_timestamp - robot_timestamp|

if delta_t < 50ms:
    直接使用  # Case A: 时间接近，直接保存
elif 50ms ≤ delta_t < 100ms:
    线性插值  # Case B: 中等延迟，插值估计
else:
    丢弃该帧  # Case C: 延迟过大，数据质量差
```

**循环缓冲区**（Circular Buffer）：
- 维护 3 个大小为 50 的缓冲区：图像、机器人状态、动作
- 每个数据点带有时间戳
- 查找时从缓冲区中选取时间最接近的数据

**数据压缩**：
- 图像使用 GZIP 压缩（HDF5 内置）
- 减少存储空间约 60-70%
- 读取时自动解压

---

### 模块 6：RobotInterface（机器人接口）

**功能**：封装 ROS2 通信，提供统一的机器人控制接口。

**ROS2 话题订阅/发布**：

| 话题 | 类型 | 方向 | 频率 | 用途 |
|------|------|------|------|------|
| `/my_gen3/joint_states` | `sensor_msgs/JointState` | 订阅 | ~100Hz | 获取关节状态 |
| `/my_gen3/joint_trajectory_controller/joint_trajectory` | `trajectory_msgs/JointTrajectory` | 发布 | 20Hz | 发送轨迹指令 |
| `/my_gen3/robotiq_gripper_controller/gripper_cmd` | `control_msgs/GripperCommand` | 动作 | 需要时 | 控制夹爪 |

**轨迹消息格式**：

```python
JointTrajectory:
  header:
    stamp: current_time
  joint_names: [joint_1, joint_2, ..., joint_7]
  points:
    - positions: [θ₁, θ₂, ..., θ₇]      # 目标关节角
      velocities: [ω₁, ω₂, ..., ω₇]    # 期望速度（有限差分）
      time_from_start: 50ms             # 到达时间
    - positions: [...]                  # 第二个点（t+100ms）
      time_from_start: 100ms
    - positions: [...]                  # 第三个点（t+150ms）
      time_from_start: 150ms
```

**保持位置（Hold Position）**：
- 离合器松开时，发送单点轨迹，位置 = 当前位置，速度 = 0
- 机器人控制器会锁定关节，保持静止

**线程安全**：
- 使用 `threading.Lock` 保护共享状态
- ROS2 回调函数在单独线程运行
- 主控制循环通过锁安全读取最新状态

---

## 主控制循环（MainLoop）

### 离合器状态机

```
              按下 A 键 (上升沿)
   空闲态 ─────────────────────▶ 遥操作态
              设置锚点
              anchor_hand = current_hand
              anchor_robot = current_ee


                    持续按住 A 键
   遥操作态 ◀────────────────────▶ 遥操作态
              计算增量 Δ = hand - anchor_hand
              机器人跟随 robot = anchor_robot + Δ * scale


              松开 A 键
   遥操作态 ─────────────────────▶ 空闲态
              保持位置
              anchor 保留（下次按下时重新设置）
```

**核心逻辑**（伪代码）：

```python
while True:
    # 1. 感知
    head_pose, hand_raw = vision_pro.get_latest()
    hand_world, rotation = ref_mgr.transform_and_filter(head_pose, hand_raw)
    hand_velocity = ref_mgr.get_velocity()

    gamepad = input_agg.get_state()
    robot_state = robot.get_state()

    # 2. 模式切换
    if gamepad.button_y_just_pressed:
        scaling = toggle_scaling()  # 1.5x ↔ 0.5x

    # 3. 安全检查
    healthy = safety.check_health(
        vision_latency=now - vision_timestamp,
        ik_history=recent_ik_results,
        joint_error=robot_state.error
    )

    # 4. 控制逻辑
    if gamepad.clutch_pressed and healthy:

        # 仅上升沿设置锚点（关键！）
        if gamepad.clutch_just_pressed:
            anchor_hand = hand_world
            anchor_robot = robot_state.ee_pose

        # 计算增量
        delta = (hand_world - anchor_hand) * scaling
        target = anchor_robot + delta

        # 安全限幅
        target = safety.clamp_to_workspace(target)

        # IK 求解
        joints = planner.solve_ik(target, rotation, seed=robot_state.joints)

        if joints is not None:
            # 生成轨迹
            traj = planner.generate_trajectory(joints, hand_velocity)
            robot.send_trajectory(traj)
        else:
            robot.hold_position()  # IK 失败时保持

        # 夹爪控制
        robot.send_gripper(gamepad.trigger_val)

        # 记录数据
        logger.log_frame(robot_state, delta, camera.image)

    else:
        # 离合器松开或不健康
        robot.hold_position()

    # 5. 定时控制（20Hz）
    sleep_until_next_cycle()
```

---

## 关键技术点深度解析

### 1. OneEuroFilter 算法原理

**问题**：传感器数据含噪声，直接使用会导致机器人抖动。

**传统低通滤波器的困境**：
- 截止频率低 → 平滑但延迟大
- 截止频率高 → 延迟小但抖动明显

**OneEuroFilter 的创新**：自适应截止频率

```python
# 核心思想：根据信号变化速度动态调整滤波强度
cutoff = min_cutoff + beta * |速度|

当手静止时（速度≈0）：
  cutoff ≈ min_cutoff（强滤波，平滑）

当手快速移动时（速度大）：
  cutoff 增大（弱滤波，响应快）
```

**数学公式**：

```
α(fc) = 1 / (1 + τ/Te)              # 平滑因子

其中：
  fc = 截止频率
  Te = 采样周期（1/20Hz = 0.05s）
  τ = 1/(2πfc)

滤波器递推：
  x̂[n] = α·x[n] + (1-α)·x̂[n-1]
```

**参数调优经验**：
- `min_cutoff = 1.0 Hz`：适合手部运动（不会太慢）
- `beta = 0.05`：中等速度敏感度
- `d_cutoff = 1.0 Hz`：速度估计的平滑度

---

### 2. 为什么需要"锚点"机制

**问题场景**：

假设不使用锚点，直接让机器人跟随手部绝对位置：

```python
# 错误方案
target = hand_world * scale  # 直接缩放
```

**问题**：
1. 手的工作空间（1m³）远大于机器人工作空间（0.6m 半径）
2. 手初始位置可能在机器人无法到达的区域
3. 无法实现"局部精细控制"

**正确方案（锚点 + 增量）**：

```python
# 按下离合器时
anchor_hand = hand_world       # 记录手的位置
anchor_robot = robot.ee_pose   # 记录机器人的位置

# 持续控制时
delta = hand_world - anchor_hand     # 手的位移
target = anchor_robot + delta * scale  # 机器人跟随位移
```

**优势**：
- ✅ 可以从任意位置开始操作
- ✅ 实现"相对控制"（类似鼠标移动）
- ✅ 支持不同缩放比例（快速/精确模式）
- ✅ 松开离合器后可以"重置"手的位置

**类比**：就像用鼠标控制光标，移动的是**增量**而非绝对位置。

---

### 3. 轨迹预测的数学原理

**一阶线性外推**：

```
假设：
  t₀ 时刻手的位置：p₀
  t₀ 时刻手的速度：v₀（通过滤波器估计）

预测 t₁ 时刻的位置：
  p₁ = p₀ + v₀ · Δt

其中 Δt = t₁ - t₀
```

**实际实现**：

```python
current_pos = [0.3, 0.2, 0.5]      # 当前手的位置
velocity = [0.1, 0.05, 0.0]        # OneEuroFilter 估计的速度

# 预测 100ms 后
dt = 0.10
predicted_pos = current_pos + velocity * dt
# = [0.31, 0.205, 0.5]

# 求解 IK
predicted_joints = solve_ik(predicted_pos, rotation)

# 加入轨迹点
trajectory.points.append({
    'positions': predicted_joints,
    'time_from_start': 100ms
})
```

**边界情况处理**：

```python
# 1. 速度钳位
velocity = np.clip(velocity, -0.5, 0.5)  # 限制 ±0.5 m/s

# 2. 边界检测
if predicted_pos 超出工作空间:
    predicted_pos = clamp_to_workspace(predicted_pos)
    # 不外推穿墙

# 3. IK 失败
if solve_ik(predicted_pos) == None:
    break  # 停止添加后续点
```

**效果**：
- 减少 50-100ms 的感知-执行延迟
- 机器人运动更流畅（不会"追赶"手部）
- 快速运动时效果尤其明显

---

### 4. 时间戳对齐的工程实践

**挑战**：

```
相机线程:    [t=100] ───── [t=150] ───── [t=200]
机器人线程:  ──── [t=120] ──── [t=170] ──── [t=220]
动作线程:    ─ [t=115] ─── [t=165] ─── [t=215]
```

不同线程产生数据的时间不同步！

**朴素方案**（错误）：

```python
# 直接保存，不对齐
logger.save(
    image=latest_image,        # t=150
    robot=latest_robot_state,  # t=170
    action=latest_action       # t=165
)
```

**问题**：时间戳不匹配，学习算法会认为 action 导致了错误的 observation。

**正确方案**（本项目实现）：

```python
# 1. 以机器人状态为基准（因为它最重要）
robot_state = get_robot_state()  # t=170
robot_time = 170

# 2. 在图像缓冲区中查找最近的
image_buffer = [
    (t=100, img1),
    (t=150, img2),
    (t=200, img3)
]

# 找到 t=150（Δt = 20ms）
nearest_image = find_nearest(image_buffer, robot_time)

# 3. 判断是否可用
delta_t = abs(150 - 170) = 20ms

if delta_t < 50ms:
    # 直接使用
    save(image=nearest_image, robot=robot_state)
elif 50ms < delta_t < 100ms:
    # 线性插值（对图像来说，实际上仍用最近的）
    interpolated = interpolate(images, robot_time)
    save(image=interpolated, robot=robot_state)
else:
    # 丢弃这一帧
    dropped_frames += 1
```

**缓冲区大小选择**：
- 50 帧 × 50ms = 2.5 秒缓冲
- 足够覆盖正常的线程调度延迟
- 过大会占用内存，过小可能找不到匹配

---

### 5. ROS2 轨迹控制器原理

**为什么不直接发送关节位置**？

```python
# 错误方案：直接发布位置
joint_position_pub.publish(target_joints)
```

**问题**：
- 没有时间约束，机器人会以最大速度移动（危险！）
- 没有速度信息，运动不平滑（会顿挫）

**正确方案：轨迹控制器**

```python
trajectory = JointTrajectory()
trajectory.points = [
    JointTrajectoryPoint(
        positions=[0.1, 0.2, ...],    # 目标位置
        velocities=[0.05, 0.1, ...],  # 期望速度
        time_from_start=50ms          # 到达时间
    ),
    # ... 更多点
]
```

**控制器行为**：
1. 接收轨迹后，插值生成平滑路径
2. 使用 PID 控制器跟踪轨迹
3. 速度前馈（feedforward）提高跟踪精度

**速度计算**（有限差分）：

```python
dt = 0.05  # 50ms
velocities = (target_joints - current_joints) / dt
```

---

## 性能优化与调试经验

### 控制循环性能

**目标**：保持 20Hz（50ms 周期）

**潜在瓶颈**：

| 操作 | 耗时 | 优化方案 |
|------|------|---------|
| Vision Pro 数据获取 | ~5ms | 已优化（gRPC 流式传输） |
| OneEuroFilter | <1ms | 纯 NumPy 计算 |
| IK 求解（KDL） | 5-20ms | ✅ 温启动 seed ✅ 限制迭代次数 |
| 轨迹生成 | <1ms | 简单数组操作 |
| ROS2 发布 | ~2ms | 异步发布 |
| 数据记录 | <1ms | 后台缓冲，不阻塞 |
| **总计** | **15-30ms** | ✅ 符合 50ms 要求 |

**优化技巧**：

1. **减少 IK 迭代次数**：
   ```python
   # 调低精度要求
   position_tolerance = 1mm  # 而非 0.1mm
   max_iterations = 20       # 而非 100
   ```

2. **跳过轨迹外推**（高负载时）：
   ```python
   if loop_time > 40ms:
       use_extrapolation = False  # 只发单点
   ```

3. **降低图像分辨率**（如果使用相机）：
   ```python
   # 640×480 → 320×240
   image = cv2.resize(image, (320, 240))
   ```

### 调试技巧

**1. 可视化手部轨迹**

```python
# 在控制循环中打印
print(f"Hand: {hand_pos}, Robot: {robot_pos}, Delta: {delta}")
```

**2. 检查 IK 成功率**

```python
# 每 100 帧打印一次
if frame_count % 100 == 0:
    success_rate = ik_successes / ik_attempts
    print(f"IK Success Rate: {success_rate:.2%}")
```

如果成功率 <90%，说明目标位置经常超出工作空间。

**3. 监控安全违规**

```python
# 在 safety_monitor 中
if violation:
    print(f"[SAFETY] {violation_reason}")
    log_to_file(violation_reason)  # 记录到日志
```

**4. 录制对比数据**

```python
# 对比手部位置和机器人位置
plt.plot(hand_trajectory_x, label='Hand')
plt.plot(robot_trajectory_x, label='Robot')
plt.legend()
plt.show()
```

查看延迟和跟踪误差。

---

## 常见问题与解决方案

### Q1: IK 求解经常失败

**现象**：打印 "⚠ IK Failed"

**原因**：
1. 目标位置超出工作空间
2. 目标姿态接近奇异点
3. 与当前位置距离过大

**解决方案**：

```python
# 1. 检查工作空间限制
safe_target = safety_monitor.clamp_to_workspace(target)

# 2. 限制单步最大位移
max_delta = 0.05  # 5cm
if norm(delta) > max_delta:
    delta = delta / norm(delta) * max_delta

# 3. 降低 IK 精度要求
position_tolerance = 5mm  # 从 1mm 放宽
```

### Q2: 机器人运动延迟大

**现象**：手移动后，机器人 1-2 秒才跟上

**排查步骤**：

1. **检查 Vision Pro 延迟**：
   ```python
   latency = time.time() - vision_timestamp
   print(f"Vision Latency: {latency*1000:.1f}ms")
   ```
   应该 <50ms，如果 >200ms 说明网络问题。

2. **检查循环周期**：
   ```python
   loop_time = time.time() - loop_start
   if loop_time > 0.05:
       print(f"Loop overrun: {loop_time*1000:.1f}ms")
   ```
   如果经常超过 50ms，考虑关闭轨迹预测。

3. **检查机器人控制器响应**：
   ```bash
   ros2 topic hz /my_gen3/joint_states
   ```
   应该 ~100Hz，如果很低说明机器人控制器有问题。

### Q3: 录制的数据质量差

**现象**：回放时发现图像和动作不匹配

**检查时间戳对齐**：

```python
stats = data_logger.get_stats()
print(f"Dropped frames: {stats['dropped_frames']}")
print(f"Interpolated frames: {stats['interpolated_frames']}")
```

如果丢帧率 >10%，说明相机帧率不足或时间戳不准。

**解决方案**：

```python
# 1. 降低相机帧率匹配控制频率
camera.set_fps(20)  # 与控制循环同步

# 2. 增大对齐阈值（降低质量要求）
alignment_threshold_ms = 100  # 从 50ms 放宽
```

### Q4: 离合器松开后机器人漂移

**现象**：松开 A 键后，机器人缓慢移动

**原因**：`hold_position()` 可能只发送位置，没有明确速度为 0

**解决方案**：

```python
def hold_position(self):
    point = JointTrajectoryPoint()
    point.positions = self.current_joints
    point.velocities = [0.0] * 7  # 明确设置速度为 0
    point.time_from_start = Duration(sec=0, nanosec=50_000_000)
```

---

## 项目亮点总结

### 技术创新点

1. **自适应滤波**：OneEuroFilter 实现低延迟平滑，平衡响应速度和稳定性
2. **预测性控制**：基于速度估计的轨迹外推，补偿系统延迟
3. **多层安全机制**：看门狗 + 工作空间 + 边界检测，确保零事故
4. **高精度时间戳对齐**：<50ms 对齐精度，保证数据质量

### 工程实践亮点

1. **模块化设计**：6 个独立模块，职责清晰，易于测试和维护
2. **配置驱动**：通过 YAML 文件调整参数，无需修改代码
3. **全面测试**：7 个集成测试全部通过，覆盖各模块和系统整体
4. **完善文档**：中英文文档 + 快速上手指南 + 技术细节文档

### 性能指标

- **控制频率**：20Hz（50ms 周期）
- **端到端延迟**：<50ms（感知到执行）
- **IK 成功率**：>95%（正常工作空间内）
- **数据质量**：丢帧率 <5%，时间戳对齐误差 <50ms
- **稳定性**：连续运行 1+ 小时无崩溃

### 应用价值

- **学术研究**：为强化学习提供高质量演示数据
- **工业应用**：可快速部署到实际遥操作场景
- **可扩展性**：支持不同机器人平台（修改 URDF 和 ROS2 话题）

---

## 技术术语表

| 术语 | 英文 | 解释 |
|------|------|------|
| 正运动学 | Forward Kinematics (FK) | 已知关节角 → 计算末端位姿 |
| 逆运动学 | Inverse Kinematics (IK) | 已知末端位姿 → 计算关节角 |
| 离合器 | Clutch | 类似汽车离合器，按下启用控制 |
| 锚点 | Anchor | 记录初始位置，用于相对控制 |
| 看门狗 | Watchdog | 监控系统健康，异常时触发保护 |
| 截止频率 | Cutoff Frequency | 滤波器参数，控制平滑程度 |
| 外推 | Extrapolation | 基于当前趋势预测未来状态 |
| 温启动 | Warm Start | 使用上次结果作为初值，加速求解 |
| 时间戳对齐 | Timestamp Alignment | 同步不同来源数据的时间 |
| 末端执行器 | End-Effector | 机械臂最前端（夹爪/工具） |

---

## 快速上手检查清单

在讨论项目时，确保能够流畅回答以下问题：

- [ ] **系统架构**：6 个模块的名称和功能
- [ ] **控制频率**：20Hz，为什么选择这个频率？
- [ ] **OneEuroFilter**：三个参数的含义和作用
- [ ] **离合器机制**：为什么需要锚点？何时设置？
- [ ] **安全机制**：四种看门狗条件 + 工作空间限制
- [ ] **IK 求解**：温启动的作用，失败如何处理
- [ ] **轨迹预测**：为什么需要预测？如何实现？
- [ ] **数据对齐**：三种对齐策略（<50ms, 50-100ms, >100ms）
- [ ] **性能优化**：主要耗时在哪里？如何优化？
- [ ] **调试经验**：遇到延迟/IK 失败/数据质量差如何排查？

---

*本文档版本：v1.0 | 最后更新：2025-01-30*
